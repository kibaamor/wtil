# CSGO

## 行为目标

1. 在短期内，agent必须控制其目标和运动，对敌人做出反应。
2. 在中期范围内，agent必须在地图区域内导航，管理其弹药并对其健康水平作出反应。
3. 从长远来看，agent应该管理其经济，计划策略，适应对手的优势和劣势，并与队友合作。

## Obs采集

1024×768 分辨率运行，截取中心 584×488 区域，再下采样到 180×80 。 以 16 帧训练。

网络后期将雷达地图、杀戮反馈，以及关于健康、弹药和剩余时间信息以矢量的形式提供。

## 动作输出

难点：

- CSGO 的输出空间混合了离散（如移动键）和连续（鼠标移动）的动作，其中鼠标控制是非常重要的。
- 这些动作并不相互排斥（例如，一个人可能同时重新装弹、跳跃和向左移动）。

| Action      | Meaning                        | Output by agent? | Output activation |
| ----------- | ------------------------------ | ---------------- | ----------------- |
| w,a,s,d     | forward, backward, left, right | yes              | sigmoid           |
| space       | jump                           | yes              | sigmoid           |
| r           | reload                         | yes              | sigmoid           |
| ctrl        | crouch                         | no               | –                 |
| shift       | walk                           | no               | –                 |
| 1,2,3,4     | weapon switch                  | no               | –                 |
| left click  | fire                           | yes              | sigmoid           |
| right click | zoom                           | no               | –                 |
| mouse x & y | aim                            | yes              | 2 x softmax       |
| value       | value estimate                 | yes              | linear            |

具体设计：

1. 将鼠标空间离散化并将其视为一个分类问题，采用了不均匀的离散化网格，中间比较细，边缘比较粗，在x轴和y轴上共有19个选项，即鼠标x，鼠标y∈{-300, -200, -100, -60, -30, -20, -10, -5, -3, -1, 0, 1, 3..., 300}。

    > 鼠标的运动可以通过X和Y坐标的变化来概括。我们试过把这些当作连续的目标，通过均方误差进行优化，但这导致了不理想的行为（例如，给定两个敌人或路径的选择，agent会在两者之间输出一个点，这使均方误差最小！）。

2. 为了解决动作空间的互斥性质，对按键和点击使用了独立的（二进制）交叉熵损失，对每个鼠标轴又使用了两个（多进制）交叉熵损失。

价值函数及奖励的设计：

$$
\begin{aligned}
v_t &= r_t + \lambda v_t + 1 \\
r_t &= 1.0 K_t - 0.5 D_t - 0.02 F_t \\
\end{aligned}
$$

其中，$K_t, D_t, F_t \in \lbrace 0, 1\rbrace$，都是二元变量，代表是否有杀戮 $K_t$ ，死亡 $D_t$ ，或开枪 $F_t$ ，折扣率 $\lambda = 0.995$ 。

## 网络结构

以EfficientNetB0为核心，用在ImageNet上预训练的权重进行初始化，但只有前四个残差块--对于180×80的输入，这输出的维度是12×5。

使用堆叠输入的方法会经常被卡在门或角落里，并在交火中忘记了敌人。最后在EfficientNetB0之后使用了卷积LSTM层解决了上述问题。

一个线性层将卷积LSTM连接到输出层。

## 动作预测

对某些动作的预测--重新装载、跳跃、射击--很少超过0.5的阈值，所以很少被argmax策略所选择，所以agent以概率方式选择这些动作。

键盘和鼠标的移动通过 argmax 选择。（如果不动超过3秒，所有的动作使用概率来选择，而不是 argmax ）。

## 训练详情

初的训练阶段，我们使用了16帧（1秒）的段长和8的批次量，然后扩展到64帧（4秒），批次量为2。
